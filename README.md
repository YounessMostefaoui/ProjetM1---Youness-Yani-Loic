# ProjetM1---Youness-Yani-Loic

ğŸ“° Fake News Detection on Bluesky â€” Guide Utilisateur --- BERT
ğŸ“¦ PrÃ©sentation du projet

Ce projet vise Ã  collecter des posts depuis la plateforme Bluesky, les stocker dans une base PostgreSQL, et Ã  entraÃ®ner un modÃ¨le de classification pour dÃ©tecter les fake news, en s'appuyant sur un ensemble de donnÃ©es fusionnÃ©es provenant de LIAR, FakeNewsNet et PHEME. Le modÃ¨le utilise BERTweet, une version optimisÃ©e de BERT pour les tweets.
ğŸ“ Structure du projet

    collect.py : collecte les posts de Bluesky et les insÃ¨re dans PostgreSQL.

    test.py : fusionne les jeux de donnÃ©es LIAR, FakeNewsNet, PHEME, les nettoie, les insÃ¨re dans PostgreSQL.

    test_berttweet.py : utilise un modÃ¨le BERTweet pour Ã©valuer les tweets collectÃ©s.

    merged_fake_news_dataset.csv : dataset fusionnÃ© prÃªt Ã  l'emploi pour l'entraÃ®nement/Ã©valuation.

âš™ï¸ PrÃ©requis
Python Packages

Installe les dÃ©pendances nÃ©cessaires :

pip install -r requirements.txt

Base de donnÃ©es PostgreSQL

Deux bases de donnÃ©es sont utilisÃ©es :

    Tweet_loic : stocke les tweets collectÃ©s sur Bluesky.

    Training : stocke les jeux de donnÃ©es annotÃ©s (LIAR, FakeNewsNet, PHEME).

ğŸ›°ï¸ 1. Script collect.py â€” Collecte de tweets sur Bluesky

Ce script :

    Se connecte Ã  l'API de Bluesky via atproto.

    Cherche jusqu'Ã  4000 posts avec un hashtag (par dÃ©faut #political).

    Filtre les posts non anglais ou peu engageants.

    Nettoie le texte (suppression des emojis, URLs, etc.).

    InsÃ¨re les tweets dans la base PostgreSQL Tweet_loic, table tweets_bluesky.

ğŸ”§ Configuration Ã  modifier

    Identifiants Bluesky :

    client.login('TON_EMAIL', 'TON_MOT_DE_PASSE')

    Connexion PostgreSQL (host, user, password, dbname).

ğŸ’» ExÃ©cution

python collect.py

ğŸ“Š 2. Script test.py â€” Fusion et insertion des datasets annotÃ©s

Ce script :

    Charge les jeux de donnÃ©es LIAR, FakeNewsNet et PHEME.

    Nettoie les textes (suppression hashtags, mentions, URLs).

    Remappe les labels (1 = vrai, 0 = fake).

    Fusionne le tout dans un DataFrame unique.

    Sauvegarde un CSV local merged_fake_news_dataset.csv.

    CrÃ©e la table fake_news dans la base Training et y insÃ¨re les donnÃ©es.

ğŸ“ Structure attendue

Assurez-vous que les fichiers suivants sont prÃ©sents dans le dossier :

    train.tsv, test.tsv, valid.tsv (pour LIAR)

    politifact_real.csv, politifact_fake.csv, gossipcop_real.csv, gossipcop_fake.csv (pour FakeNewsNet)

    Dossier phemerumourschemedataset/pheme-rumour-scheme-dataset/threads/en (pour PHEME)

ğŸ’» ExÃ©cution

python test.py

ğŸ¤– 3. Script test_berttweet.py â€” DÃ©tection de fake news via BERTweet

Ce script (incomplet dans l'extrait fourni) :

    Se connecte Ã  la base Tweet_loic.

    Charge les tweets collectÃ©s.

    Applique un modÃ¨le BERTweet (vinai/bertweet-base ou fine-tunÃ©) pour prÃ©dire leur fiabilitÃ©.

    Affiche ou sauvegarde les prÃ©dictions.

ğŸ“Œ Ã€ complÃ©ter

    Le chargement des donnÃ©es et lâ€™infÃ©rence du modÃ¨le semblent inachevÃ©s.

    Ajouter :

        Chargement du tokenizer + modÃ¨le AutoTokenizer/AutoModelForSequenceClassification

        Traitement batch des tweets

        Sauvegarde ou affichage des rÃ©sultats

ğŸ—ƒï¸ Structure des tables PostgreSQL
Table tweets_bluesky (Tweet_loic)
Colonne	Type	Description
date	TIMESTAMP	Date de crÃ©ation du tweet
auteur	TEXT	Identifiant de l'auteur
likes	INT	Nombre de likes
reposts	INT	Nombre de reposts
replies	INT	Nombre de rÃ©ponses
total_interactions	INT	Somme des likes, reposts, rÃ©ponses
contenu	TEXT	Texte brut du post
sujet_principal	TEXT	Mot-clÃ© principal extrait
texte_nettoye	TEXT	Texte nettoyÃ© pour NLP
Table fake_news (Training)
Colonne	Type	Description
text	TEXT	Texte nettoyÃ©
label	INTEGER	1 = vrai, 0 = fake
source	VARCHAR	Nom de la source (LIAR, FNN, PHEME)
ğŸ§ª Test rapide (pipeline minimal)

# Ã‰tape 1 : collecter les tweets
python collect.py

# Ã‰tape 2 : prÃ©parer le jeu de donnÃ©es annotÃ©
python test.py

# Ã‰tape 3 : exÃ©cuter l'analyse BERTweet
python test_berttweet.py  # une fois complÃ©tÃ©

ğŸš§ Ã€ amÃ©liorer

    SÃ©curisation des identifiants (via .env)

    Ajout dâ€™un script dâ€™Ã©valuation de performance (accuracy, F1-score)

    Option CLI pour choisir hashtag ou volume

    Interface web (ex: Dash/Streamlit) pour visualisation en direct


    ğŸ“° Fake News Detection on Bluesky â€” Guide Utilisateur --- Regression Logistic


âš™ï¸ PrÃ©requis
ğŸ“¦ Librairies Python

Installer les dÃ©pendances :

pip install -r requirements.txt

requirements.txt :

atproto
emoji
langdetect
pandas
scikit-learn
joblib
sqlalchemy
psycopg2

ğŸ˜ PostgreSQL

Une base PostgreSQL doit Ãªtre en place (modifiable dans test.py).

CREATE DATABASE Tweet_loic;

ğŸ§© DÃ©tail des scripts
ğŸ“¥ collect.py â€“ RÃ©cupÃ©ration de tweets depuis Bluesky
ğŸ¯ Objectif :

    Se connecter Ã  lâ€™API Bluesky.

    Collecter les posts contenant un hashtag donnÃ©.

    Nettoyer et filtrer les posts (langue anglaise, interactions significatives).

    Sauvegarder les donnÃ©es dans tweets_bluesky_.csv.

ğŸ”§ ParamÃ¨tres clÃ©s :

    Hashtag : modifiable dans hashtag = "political"

    Limite : 4000 posts par dÃ©faut

    Filtrage :

        Langue : anglais uniquement

        Suppression des emojis, URL, symboles

        Filtrage des posts avec interactions faibles (â‰¤1)

â–¶ï¸ ExÃ©cution :

python collect.py

Le fichier tweets_bluesky_.csv contiendra :
date	auteur	likes	reposts	replies	total_interactions	contenu	sujet_principal	texte_nettoye
ğŸ§  traitement.py â€“ EntraÃ®nement du modÃ¨le ML
ğŸ¯ Objectif :

    Charger le dataset train.tsv (dataset LIAR).

    Nettoyer les textes.

    Transformer les labels en binaire (fake vs true).

    EntraÃ®ner un modÃ¨le de rÃ©gression logistique avec TF-IDF.

    Sauvegarder le modÃ¨le et le vectorizer.

ğŸ”§ DÃ©tails :

    Mapping des labels :

        pants-fire, false, barely-true â†’ 0 (Fake)

        half-true, mostly-true, true â†’ 1 (True)

    Nettoyage : suppression emojis, ponctuation, URL, etc.

ğŸ“¦ Sorties :

    modele_fakenews.joblib

    vectorizer_fakenews.joblib

    tweets_avec_score.csv (si prÃ©diction directe sur tweets_bluesky_.csv)

â–¶ï¸ ExÃ©cution :

python traitement.py

ğŸ”® test.py â€“ Application du modÃ¨le sur les donnÃ©es Bluesky
ğŸ¯ Objectif :

    Charger les tweets nettoyÃ©s depuis PostgreSQL.

    Charger le modÃ¨le et le vectorizer.

    Appliquer le modÃ¨le sur les textes.

    Ã‰crire les scores de fiabilitÃ© dans une nouvelle table.

ğŸ˜ Connexion PostgreSQL :

Modifiable dans ces lignes :

host = "localhost"
port = "5432"
database = "Tweet_loic"
user = "postgres"
password = "123"

ğŸ“¦ Table attendue :

Table tweets_bluesky avec la colonne texte_nettoye.
ğŸ“¦ Table crÃ©Ã©e :

tweets_bluesky_scores avec colonnes :
| id | date | auteur | score_fiabilite |
â–¶ï¸ ExÃ©cution :

python test.py

ğŸ“ˆ Exemple d'utilisation

# Ã‰tape 1 : Collecte de donnÃ©es
python collect.py

# Ã‰tape 2 : EntraÃ®nement modÃ¨le
python traitement.py

# Ã‰tape 3 : Application du modÃ¨le sur nouveaux tweets
python test.py

ğŸ›¡ï¸ SÃ©curitÃ© et bonnes pratiques

    Ne jamais versionner vos identifiants Bluesky : stockez-les dans un fichier .env ou utilisez des variables dâ€™environnement.

    VÃ©rifiez que modele_fakenews.joblib nâ€™est pas sur-appris (overfitting).

    Vous pouvez tester avec d'autres modÃ¨les : SVM, RandomForest, BERTweet (via HuggingFace).

ğŸ”­ Perspectives

    AmÃ©liorer la dÃ©tection avec des modÃ¨les plus puissants (BERTweet).

    Ajouter une analyse visuelle des scores (via Dash, Plotly...).

    Ã‰tendre la dÃ©tection aux tweets en franÃ§ais.

    Mesurer lâ€™empreinte carbone des modÃ¨les.